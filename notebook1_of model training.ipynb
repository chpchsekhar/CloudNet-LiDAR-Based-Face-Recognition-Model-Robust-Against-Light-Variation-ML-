{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r2VADqhLwhIz",
        "outputId": "864ab78e-9dcd-4598-e20d-348c147de40a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "‚úÖ Loaded 240 samples with 12 classes\n",
            "Train size: 192, Test size: 48\n",
            "‚úÖ FaceNet model loaded successfully!\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 4s/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9s/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚úÖ Classification Accuracy: 0.9166666666666666\n",
            "\n",
            "üìä Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           1       0.88      1.00      0.93         7\n",
            "          10       1.00      1.00      1.00         4\n",
            "          11       1.00      1.00      1.00         2\n",
            "          12       1.00      1.00      1.00         3\n",
            "           2       1.00      0.67      0.80         3\n",
            "           3       0.80      0.80      0.80         5\n",
            "           4       1.00      1.00      1.00         2\n",
            "           5       1.00      1.00      1.00         5\n",
            "           6       1.00      1.00      1.00         5\n",
            "           7       1.00      1.00      1.00         3\n",
            "           8       0.50      1.00      0.67         2\n",
            "           9       1.00      0.71      0.83         7\n",
            "\n",
            "    accuracy                           0.92        48\n",
            "   macro avg       0.93      0.93      0.92        48\n",
            "weighted avg       0.94      0.92      0.92        48\n",
            "\n",
            "\n",
            "‚úÖ All models and encoders are saved in: /content/drive/MyDrive/saved_models\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import joblib\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications import InceptionResNetV2\n",
        "from tensorflow.keras.layers import Input\n",
        "\n",
        "# ------------------------------\n",
        "# 1Ô∏è‚É£ **Mount Google Drive**\n",
        "# ------------------------------\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# ------------------------------\n",
        "# 2Ô∏è‚É£ **Load .npy Files into Memory**\n",
        "# ------------------------------\n",
        "DATA_DIR = \"/content/drive/MyDrive/real_cloud_data\"\n",
        "\n",
        "def load_data(data_dir):\n",
        "    \"\"\"Load images and labels from .npy files.\"\"\"\n",
        "    X, y = [], []\n",
        "\n",
        "    for label in sorted(os.listdir(data_dir)):  # Folders named 1, 2, 3, ...\n",
        "        class_dir = os.path.join(data_dir, label)\n",
        "\n",
        "        if os.path.isdir(class_dir):\n",
        "            for npy_file in os.listdir(class_dir):\n",
        "                if npy_file.endswith('.npy'):\n",
        "                    file_path = os.path.join(class_dir, npy_file)\n",
        "                    data = np.load(file_path)\n",
        "\n",
        "                    # Ensure valid image format\n",
        "                    if data.ndim == 3:  # (H, W, C)\n",
        "                        X.append(data)\n",
        "                        y.append(label)\n",
        "\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "# Load the dataset\n",
        "X, y = load_data(DATA_DIR)\n",
        "print(f\"‚úÖ Loaded {len(X)} samples with {len(np.unique(y))} classes\")\n",
        "\n",
        "# ------------------------------\n",
        "# 3Ô∏è‚É£ **Preprocess the Data**\n",
        "# ------------------------------\n",
        "# Normalize the images for FaceNet\n",
        "X = X / 255.0\n",
        "\n",
        "# Encode class labels into integers\n",
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(y)\n",
        "\n",
        "# Split into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"Train size: {len(X_train)}, Test size: {len(X_test)}\")\n",
        "\n",
        "# ------------------------------\n",
        "# 4Ô∏è‚É£ **Load Pretrained FaceNet Model**\n",
        "# ------------------------------\n",
        "def build_facenet_model():\n",
        "    base_model = InceptionResNetV2(weights='imagenet', include_top=False, input_shape=(160, 160, 3))\n",
        "    x = base_model.output\n",
        "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "    model = Model(inputs=base_model.input, outputs=x)\n",
        "    return model\n",
        "\n",
        "facenet = build_facenet_model()\n",
        "print(\"‚úÖ FaceNet model loaded successfully!\")\n",
        "\n",
        "# ------------------------------\n",
        "# 5Ô∏è‚É£ **Resize and Fix Image Channels**\n",
        "# ------------------------------\n",
        "def resize_images(images, target_size=(160, 160)):\n",
        "    \"\"\"Resize images to 160x160 and ensure 3 channels.\"\"\"\n",
        "    resized_images = []\n",
        "\n",
        "    for img in images:\n",
        "        img_resized = tf.image.resize(img, target_size)\n",
        "\n",
        "        # Ensure it has 3 channels (convert RGBA to RGB)\n",
        "        if img_resized.shape[-1] == 4:\n",
        "            img_resized = img_resized[..., :3]  # Keep only RGB channels\n",
        "\n",
        "        resized_images.append(img_resized)\n",
        "\n",
        "    return np.array(resized_images)\n",
        "\n",
        "# Resize images\n",
        "X_train_resized = resize_images(X_train)\n",
        "X_test_resized = resize_images(X_test)\n",
        "\n",
        "# ------------------------------\n",
        "# 6Ô∏è‚É£ **Extract Face Embeddings**\n",
        "# ------------------------------\n",
        "def get_embeddings(model, images):\n",
        "    \"\"\"Get face embeddings and handle 4-channel images.\"\"\"\n",
        "    # Ensure all images have 3 channels\n",
        "    images_fixed = np.array([img[..., :3] if img.shape[-1] == 4 else img for img in images])\n",
        "\n",
        "    embeddings = model.predict(images_fixed)\n",
        "    return embeddings\n",
        "\n",
        "# Extract face embeddings\n",
        "train_embeddings = get_embeddings(facenet, X_train_resized)\n",
        "test_embeddings = get_embeddings(facenet, X_test_resized)\n",
        "\n",
        "# ------------------------------\n",
        "# 7Ô∏è‚É£ **Train the Classifier**\n",
        "# ------------------------------\n",
        "# Normalize embeddings\n",
        "scaler = StandardScaler()\n",
        "train_embeddings = scaler.fit_transform(train_embeddings)\n",
        "test_embeddings = scaler.transform(test_embeddings)\n",
        "\n",
        "# Use SVM for classification\n",
        "svm_classifier = SVC(kernel='linear', probability=True)\n",
        "svm_classifier.fit(train_embeddings, y_train)\n",
        "\n",
        "# ------------------------------\n",
        "# 8Ô∏è‚É£ **Evaluate the Model**\n",
        "# ------------------------------\n",
        "y_pred = svm_classifier.predict(test_embeddings)\n",
        "\n",
        "# Print accuracy and classification report\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"\\n‚úÖ Classification Accuracy:\", accuracy)\n",
        "print(\"\\nüìä Classification Report:\\n\", classification_report(y_test, y_pred, target_names=le.classes_))\n",
        "\n",
        "# ------------------------------\n",
        "# 9Ô∏è‚É£ **Create Folder & Save Models**\n",
        "# ------------------------------\n",
        "# Define directory to save models\n",
        "SAVE_DIR = \"/content/drive/MyDrive/saved_models\"\n",
        "os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "\n",
        "# Save models and preprocessing files into the directory\n",
        "joblib.dump(svm_classifier, os.path.join(SAVE_DIR, 'svm_classifier.pkl'))\n",
        "joblib.dump(scaler, os.path.join(SAVE_DIR, 'scaler.pkl'))\n",
        "joblib.dump(le, os.path.join(SAVE_DIR, 'label_encoder.pkl'))\n",
        "facenet.save(os.path.join(SAVE_DIR, 'facenet_model.h5'))\n",
        "\n",
        "print(\"\\n‚úÖ All models and encoders are saved in:\", SAVE_DIR)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YTX3WHbyw-of",
        "outputId": "415e728a-6bbe-414c-e054-fda37cbc7514"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    }
  ]
}